{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-30T16:28:45.625471Z","iopub.execute_input":"2021-11-30T16:28:45.625792Z","iopub.status.idle":"2021-11-30T16:28:49.087482Z","shell.execute_reply.started":"2021-11-30T16:28:45.625762Z","shell.execute_reply":"2021-11-30T16:28:49.086497Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\ntfk = tf.keras\ntf.keras.backend.set_floatx(\"float64\")\nimport tensorflow_probability as tfp\ntfd = tfp.distributions\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import IsolationForest\n#setting up helper fucntions\nscaler = StandardScaler()\ndetector = IsolationForest(n_estimators=1000, behaviour=\"deprecated\", contamination=\"auto\", random_state=0)\nneg_log_likelihood = lambda x, rv_x: -rv_x.log_prob(x)\n#storing the data in a variable\ndata = pd.read_csv('../input/clothing-dataset-full/images.csv')\ndata.head()\n","metadata":{"execution":{"iopub.status.busy":"2021-11-30T16:28:49.089050Z","iopub.execute_input":"2021-11-30T16:28:49.089343Z","iopub.status.idle":"2021-11-30T16:28:49.114305Z","shell.execute_reply.started":"2021-11-30T16:28:49.089310Z","shell.execute_reply":"2021-11-30T16:28:49.113713Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"data = data[['image','label']].groupby('label').count() #error at times but works fine the other times, why?","metadata":{"execution":{"iopub.status.busy":"2021-11-30T16:32:57.046018Z","iopub.execute_input":"2021-11-30T16:32:57.046705Z","iopub.status.idle":"2021-11-30T16:32:57.081308Z","shell.execute_reply.started":"2021-11-30T16:32:57.046659Z","shell.execute_reply":"2021-11-30T16:32:57.080156Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"data = data[['image','label']].groupby('label').count()","metadata":{"execution":{"iopub.status.busy":"2021-11-30T16:30:15.729534Z","iopub.execute_input":"2021-11-30T16:30:15.730085Z","iopub.status.idle":"2021-11-30T16:30:15.762998Z","shell.execute_reply.started":"2021-11-30T16:30:15.730029Z","shell.execute_reply":"2021-11-30T16:30:15.761776Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"category_cnt = data[['image','label']].groupby('label').count() #error at times but works at other times, why is that?\ncategory_cnt.plot.bar() #error at times but works at other times, why is that?","metadata":{"execution":{"iopub.status.busy":"2021-11-30T16:28:49.126592Z","iopub.execute_input":"2021-11-30T16:28:49.126849Z","iopub.status.idle":"2021-11-30T16:28:49.164955Z","shell.execute_reply.started":"2021-11-30T16:28:49.126821Z","shell.execute_reply":"2021-11-30T16:28:49.163802Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# training setup\ninputs = [\"image\", \"label\"]\nn_epochs = 35\nn_samples = data.shape[0]\nn_batches = 8\nbatch_size = np.floor(n_samples/8)\nbuffer_size = data.shape[0]\n\nn_train = int(0.7*data.shape[0])\n#training Bayesian Neural Network\n#cutting/partitioning data\ndata = tf.data.Dataset.from_tensor_slices((data[inputs].values, data[inputs].values))\ndata = data.shuffle(n_samples, reshuffle_each_iteration=True)\n#training data and taking respective data\ndata_train = data.take(n_train).batch(batch_size).repeat(n_epochs)\ndata_test = data.skip(n_train).batch(1)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-30T16:28:49.166118Z","iopub.status.idle":"2021-11-30T16:28:49.166468Z","shell.execute_reply.started":"2021-11-30T16:28:49.166271Z","shell.execute_reply":"2021-11-30T16:28:49.166287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Starting preprocessing/training\nprior = tfd.Independent(tfd.Normal(loc=tf.zeros(len(inputs), dtype=tf.float64), scale=1.0), reinterpreted_batch_ndims=1)\n\nmodel = tfk.Sequential([\ntfk.layers.InputLayer(input_shape=(len(inputs),), name=\"input\"),\ntfk.layers.Dense(10, activation=\"relu\", name=\"dense_1\"),\ntfk.layers.Dense(tfp.layers.MultivariateNormalTriL.params_size(\nlen(inputs)), activation=None, name=\"distribution_weights\"),\ntfp.layers.MultivariateNormalTriL(len(inputs), activity_regularizer=tfp.layers.KLDivergenceRegularizer(prior, weight=1/n_batches), name=\"inputs\")\n], name=\"model\")\nmodel.compile(optimizer=\"adam\", loss=neg_log_likelihood)\n#running training session\nmodel.fit(data_train, epochs=n_epochs, validation_data=data_test, verbose=False)\nmodel.summary()\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-30T16:28:49.169769Z","iopub.status.idle":"2021-11-30T16:28:49.170081Z","shell.execute_reply.started":"2021-11-30T16:28:49.169919Z","shell.execute_reply":"2021-11-30T16:28:49.169936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define prior for regularization.\nprior = tfd.Independent(tfd.Normal(loc=tf.zeros(len(outputs), dtype=tf.float64), scale=1.0), reinterpreted_batch_ndims=1)\n# Define model instance.\nmodel = tfk.Sequential([\ntfk.layers.InputLayer(input_shape=(len(inputs),), name=\"input\"),\ntfk.layers.Dense(10, activation=\"relu\", name=\"dense_1\"),\ntfk.layers.Dense(tfp.layers.MultivariateNormalTriL.params_size(\nlen(outputs)), activation=None, name=\"distribution_weights\"),\ntfp.layers.MultivariateNormalTriL(len(outputs), activity_regularizer=tfp.layers.KLDivergenceRegularizer(prior, weight=1/n_batches), name=\"output\")\n], name=\"model\")\n# Compile model.\nmodel.compile(optimizer=\"adam\", loss=neg_log_likelihood)\n# Run training session.\nmodel.fit(data_train, epochs=n_epochs, validation_data=data_test, verbose=False)\n# Describe model.\nmodel.summary()\n","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"tfp.layers.DenseFlipout(10, activation=\"relu\", name=\"dense_1\")","metadata":{"execution":{"iopub.status.busy":"2021-11-30T16:28:49.171104Z","iopub.status.idle":"2021-11-30T16:28:49.171423Z","shell.execute_reply.started":"2021-11-30T16:28:49.171251Z","shell.execute_reply":"2021-11-30T16:28:49.171268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(data_train, epochs=n_epochs, validation_data=data_test, verbose=False)\n\n# starting to predict data\nsamples = 200\niterations = 15\ntest_iterator = tf.compat.v1.data.make_one_shot_iterator(data_test)\nX_true, Y_true, Y_pred = np.empty(shape=(samples, len(inputs))), np.empty(shape=(samples, len(inputs))), np.empty(shape=(samples, len(inputs), iterations))\nfor i in range(samples):\n    features, labels = test_iterator.get_next()\n    X_true[i,:] = features\n    Y_true[i,:] = labels.numpy()\n    for k in range(iterations):\n        Y_pred[i,:,k] = model.predict(features)\n        \n# Calculating mean and standard deviation \nY_pred_m = np.mean(Y_pred, axis=-1)\nY_pred_s = np.std(Y_pred, axis=-1)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T16:28:49.172495Z","iopub.status.idle":"2021-11-30T16:28:49.172830Z","shell.execute_reply.started":"2021-11-30T16:28:49.172635Z","shell.execute_reply":"2021-11-30T16:28:49.172670Z"},"trusted":true},"execution_count":null,"outputs":[]}]}